{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "97084aed",
   "metadata": {},
   "source": [
    "## PASO 0 EXTRACCION DE DATOS (df_v0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4dfbdc5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_bind_date</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>2014-10-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>YES</td>\n",
       "      <td>71610</td>\n",
       "      <td>6510</td>\n",
       "      <td>13020</td>\n",
       "      <td>52080</td>\n",
       "      <td>Saab</td>\n",
       "      <td>92x</td>\n",
       "      <td>2004</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>2006-06-27</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5070</td>\n",
       "      <td>780</td>\n",
       "      <td>780</td>\n",
       "      <td>3510</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>2000-09-06</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NO</td>\n",
       "      <td>34650</td>\n",
       "      <td>7700</td>\n",
       "      <td>3850</td>\n",
       "      <td>23100</td>\n",
       "      <td>Dodge</td>\n",
       "      <td>RAM</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>1990-05-25</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>NO</td>\n",
       "      <td>63400</td>\n",
       "      <td>6340</td>\n",
       "      <td>6340</td>\n",
       "      <td>50720</td>\n",
       "      <td>Chevrolet</td>\n",
       "      <td>Tahoe</td>\n",
       "      <td>2014</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>2014-06-06</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NO</td>\n",
       "      <td>6500</td>\n",
       "      <td>1300</td>\n",
       "      <td>650</td>\n",
       "      <td>4550</td>\n",
       "      <td>Accura</td>\n",
       "      <td>RSX</td>\n",
       "      <td>2009</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>941851</td>\n",
       "      <td>1991-07-16</td>\n",
       "      <td>OH</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1310.80</td>\n",
       "      <td>0</td>\n",
       "      <td>431289</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>87200</td>\n",
       "      <td>17440</td>\n",
       "      <td>8720</td>\n",
       "      <td>61040</td>\n",
       "      <td>Honda</td>\n",
       "      <td>Accord</td>\n",
       "      <td>2006</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>285</td>\n",
       "      <td>41</td>\n",
       "      <td>186934</td>\n",
       "      <td>2014-01-05</td>\n",
       "      <td>IL</td>\n",
       "      <td>100/300</td>\n",
       "      <td>1000</td>\n",
       "      <td>1436.79</td>\n",
       "      <td>0</td>\n",
       "      <td>608177</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108480</td>\n",
       "      <td>18080</td>\n",
       "      <td>18080</td>\n",
       "      <td>72320</td>\n",
       "      <td>Volkswagen</td>\n",
       "      <td>Passat</td>\n",
       "      <td>2015</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>130</td>\n",
       "      <td>34</td>\n",
       "      <td>918516</td>\n",
       "      <td>2003-02-17</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>500</td>\n",
       "      <td>1383.49</td>\n",
       "      <td>3000000</td>\n",
       "      <td>442797</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>YES</td>\n",
       "      <td>67500</td>\n",
       "      <td>7500</td>\n",
       "      <td>7500</td>\n",
       "      <td>52500</td>\n",
       "      <td>Suburu</td>\n",
       "      <td>Impreza</td>\n",
       "      <td>1996</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>533940</td>\n",
       "      <td>2011-11-18</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1356.92</td>\n",
       "      <td>5000000</td>\n",
       "      <td>441714</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>YES</td>\n",
       "      <td>46980</td>\n",
       "      <td>5220</td>\n",
       "      <td>5220</td>\n",
       "      <td>36540</td>\n",
       "      <td>Audi</td>\n",
       "      <td>A5</td>\n",
       "      <td>1998</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>456</td>\n",
       "      <td>60</td>\n",
       "      <td>556080</td>\n",
       "      <td>1996-11-11</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>766.19</td>\n",
       "      <td>0</td>\n",
       "      <td>612260</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5060</td>\n",
       "      <td>460</td>\n",
       "      <td>920</td>\n",
       "      <td>3680</td>\n",
       "      <td>Mercedes</td>\n",
       "      <td>E400</td>\n",
       "      <td>2007</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer  age  policy_number policy_bind_date policy_state  \\\n",
       "0                   328   48         521585       2014-10-17           OH   \n",
       "1                   228   42         342868       2006-06-27           IN   \n",
       "2                   134   29         687698       2000-09-06           OH   \n",
       "3                   256   41         227811       1990-05-25           IL   \n",
       "4                   228   44         367455       2014-06-06           IL   \n",
       "..                  ...  ...            ...              ...          ...   \n",
       "995                   3   38         941851       1991-07-16           OH   \n",
       "996                 285   41         186934       2014-01-05           IL   \n",
       "997                 130   34         918516       2003-02-17           OH   \n",
       "998                 458   62         533940       2011-11-18           IL   \n",
       "999                 456   60         556080       1996-11-11           OH   \n",
       "\n",
       "    policy_csl  policy_deductable  policy_annual_premium  umbrella_limit  \\\n",
       "0      250/500               1000                1406.91               0   \n",
       "1      250/500               2000                1197.22         5000000   \n",
       "2      100/300               2000                1413.14         5000000   \n",
       "3      250/500               2000                1415.74         6000000   \n",
       "4     500/1000               1000                1583.91         6000000   \n",
       "..         ...                ...                    ...             ...   \n",
       "995   500/1000               1000                1310.80               0   \n",
       "996    100/300               1000                1436.79               0   \n",
       "997    250/500                500                1383.49         3000000   \n",
       "998   500/1000               2000                1356.92         5000000   \n",
       "999    250/500               1000                 766.19               0   \n",
       "\n",
       "     insured_zip  ... witnesses police_report_available total_claim_amount  \\\n",
       "0         466132  ...         2                     YES              71610   \n",
       "1         468176  ...         0                     NaN               5070   \n",
       "2         430632  ...         3                      NO              34650   \n",
       "3         608117  ...         2                      NO              63400   \n",
       "4         610706  ...         1                      NO               6500   \n",
       "..           ...  ...       ...                     ...                ...   \n",
       "995       431289  ...         1                     NaN              87200   \n",
       "996       608177  ...         3                     NaN             108480   \n",
       "997       442797  ...         3                     YES              67500   \n",
       "998       441714  ...         1                     YES              46980   \n",
       "999       612260  ...         3                     NaN               5060   \n",
       "\n",
       "    injury_claim property_claim  vehicle_claim   auto_make auto_model  \\\n",
       "0           6510          13020          52080        Saab        92x   \n",
       "1            780            780           3510    Mercedes       E400   \n",
       "2           7700           3850          23100       Dodge        RAM   \n",
       "3           6340           6340          50720   Chevrolet      Tahoe   \n",
       "4           1300            650           4550      Accura        RSX   \n",
       "..           ...            ...            ...         ...        ...   \n",
       "995        17440           8720          61040       Honda     Accord   \n",
       "996        18080          18080          72320  Volkswagen     Passat   \n",
       "997         7500           7500          52500      Suburu    Impreza   \n",
       "998         5220           5220          36540        Audi         A5   \n",
       "999          460            920           3680    Mercedes       E400   \n",
       "\n",
       "    auto_year fraud_reported  \n",
       "0        2004              Y  \n",
       "1        2007              Y  \n",
       "2        2007              N  \n",
       "3        2014              Y  \n",
       "4        2009              N  \n",
       "..        ...            ...  \n",
       "995      2006              N  \n",
       "996      2015              N  \n",
       "997      1996              N  \n",
       "998      1998              N  \n",
       "999      2007              N  \n",
       "\n",
       "[1000 rows x 39 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#REALIZAMOS LA EXTRACCION DE DATOS\n",
    "import pandas as pd\n",
    "df_v0 = pd.read_csv('Practica insurance_claims.csv',na_values =\"?\")\n",
    "\n",
    "df_v0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf88a109",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "months_as_customer              391\n",
       "age                              46\n",
       "policy_number                  1000\n",
       "policy_bind_date                951\n",
       "policy_state                      3\n",
       "policy_csl                        3\n",
       "policy_deductable                 3\n",
       "policy_annual_premium           991\n",
       "umbrella_limit                   11\n",
       "insured_zip                     995\n",
       "insured_sex                       2\n",
       "insured_education_level           7\n",
       "insured_occupation               14\n",
       "insured_hobbies                  20\n",
       "insured_relationship              6\n",
       "capital-gains                   338\n",
       "capital-loss                    354\n",
       "incident_date                    60\n",
       "incident_type                     4\n",
       "collision_type                    3\n",
       "incident_severity                 4\n",
       "authorities_contacted             5\n",
       "incident_state                    7\n",
       "incident_city                     7\n",
       "incident_location              1000\n",
       "incident_hour_of_the_day         24\n",
       "number_of_vehicles_involved       4\n",
       "property_damage                   2\n",
       "bodily_injuries                   3\n",
       "witnesses                         4\n",
       "police_report_available           2\n",
       "total_claim_amount              763\n",
       "injury_claim                    638\n",
       "property_claim                  626\n",
       "vehicle_claim                   726\n",
       "auto_make                        14\n",
       "auto_model                       39\n",
       "auto_year                        21\n",
       "fraud_reported                    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#COMPROBAMOS LOS DATOS ÚNICOS DE TODAS LAS COLUMNAS\n",
    "df_v0.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a9ec5",
   "metadata": {},
   "source": [
    "## PASO 1 TRAS ANALIZAR CADA VARIABLE SEGUIRÉ LAS SIGUIENTES MODIFICACIONES PARA CADA VARIABLE:\n",
    "    \n",
    "    months_as_customer              391 -> C1: agrupar en grupos de 5 años\n",
    "    age                              46 -> C1: Agrupar en grupos de 5 en cinco años\n",
    "    policy_number                  1000 -> Eliminar\n",
    "    policy_bind_date                951 -> Eliminar\n",
    "    policy_state                      3 -> OneHotEncoder\n",
    "    policy_csl                        3 -> OneHotEncoder\n",
    "    policy_deductable                 3 -> OneHotEncoder\n",
    "    policy_annual_premium           991 -> Kbins discretizer\n",
    "    umbrella_limit                   11 -> OneHotEncoder\n",
    "    insured_zip                     995 -> Eliminar\n",
    "    insured_sex                       2 -> OneHotEncoder\n",
    "    insured_education_level           7 -> LabelEncoder\n",
    "    insured_occupation               14 -> LabelEncoder\n",
    "    insured_hobbies                  20 -> LabelEncoder\n",
    "    insured_relationship              6 -> LabelEncoder\n",
    "    capital-gains                   338 -> Kbins discretizer\n",
    "    capital-loss                    354 -> Kbins discretizer\n",
    "    incident_date                    60 -> Convertir a día de la semana\n",
    "    incident_type                     4 -> OneHotEncoder\n",
    "    collision_type                    3 -> C1: SimpleImputer(mostfrecuent), C2: SimpleImputer(value), OneHotEncoder\n",
    "    incident_severity                 4 -> OneHotEncoder\n",
    "    authorities_contacted             5 -> OneHotEncoder\n",
    "    incident_state                    7 -> OneHotEncoder\n",
    "    incident_city                     7 -> OneHotEncoder\n",
    "    incident_location              1000 -> Eliminar\n",
    "    incident_hour_of_the_day         24 -> Convertir en rangos horarios\n",
    "    number_of_vehicles_involved       4 -> Nada\n",
    "    property_damage                   2 -> C1: SimpleImputer(mostfrecuent), C2: SimpleImputer(value),OneHotEncoder\n",
    "    bodily_injuries                   3 -> Nada\n",
    "    witnesses                         4 -> Nada\n",
    "    police_report_available           2 -> C1: SimpleImputer(mostfrecuent), C2: (value), OneHotEncoder\n",
    "    total_claim_amount              763 -> Kbins discretizer\n",
    "    injury_claim                    638 -> Kbins discretizer\n",
    "    property_claim                  626 -> Kbins discretizer\n",
    "    vehicle_claim                   726 -> Kbins discretizer\n",
    "    auto_make                        14 -> LabelEncoder\n",
    "    auto_model                       39 -> LabelEncoder\n",
    "    auto_year                        21 -> LabelEncoderc\n",
    "    fraud_reported                    2 -> LabelEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a28bb67a",
   "metadata": {},
   "source": [
    "## PASO 2 CREACIÓN DE NUEVAS VARIABLES Y POSTERIOR CODIFICACIÓN A CATEGÓRICO (df_v01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2f92d713",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime as dt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#TODAS LAS NUEVAS COLUMNAS SE CREARAN Y AÑADIRAN EN EL NUEVO DATAFRAME df_v01\n",
    "df_v01 = pd.DataFrame()\n",
    "\n",
    "#AGRUPAMOS EDADES DE 5 EN 5 en la columna \"age\"\n",
    "df_v01[\"age_TOAGEGROUP\"]=np.floor(df_v0[\"age\"].values/5).astype(int)\n",
    "\n",
    "#CONVERTIMOS MESES COMO CLIENTES EN AÑOS COMO CLIENTES en la columna \"months_as_customer\"\n",
    "df_v01[\"months_as_customer_TOYEAR\"]=np.floor(df_v0[\"months_as_customer\"].values/12).astype(int)\n",
    "\n",
    "\n",
    "#CONVERTIMOS EL DÍA DE INCIDENTE EN DÍA DE LA SEMANA  en la columna 'incident_date'\n",
    "df_v01['incident_date_TOWEEKDAY'] = pd.to_datetime(df_v0['incident_date'], yearfirst=True).dt.dayofweek\n",
    "\n",
    "#CONVERTIMOS LA HORA DEL DÍA EN LA PARTE DEL DÍA en la columna \"incident_hour_of_the_day\"\n",
    "df_v01[\"incident_hour_of_the_day_TOPARTOFTHEDAY\"] = df_v0[\"incident_hour_of_the_day\"]\n",
    "b = [0,4,8,12,16,20,24]\n",
    "l = ['Late Night', 'Early Morning','Morning','Noon','Eve','Night']\n",
    "df_v01[\"incident_hour_of_the_day_TOPARTOFTHEDAY\"] = pd.cut(df_v01[\"incident_hour_of_the_day_TOPARTOFTHEDAY\"], bins=b, labels=l, include_lowest=True)\n",
    "\n",
    "\n",
    "#CREAMOS COLUMNAS CON VALORES IMPUTADOS COMO CATEGORÍA DESCONOCIDO\n",
    "\n",
    "fill_na_mean = lambda x : x.fillna(\"UNKNOWN\")\n",
    "# df.transform(fill_na_mean)\n",
    "\n",
    "df_v01[\"collision_type_TOUNKNOWNIMP\"] = df_v0[\"collision_type\"].transform(fill_na_mean)\n",
    "df_v01[\"property_damage_TOUNKNOWNIMP\"] = df_v0[\"property_damage\"].transform(fill_na_mean)\n",
    "df_v01[\"police_report_available_TOUNKNOWNIMP\"] = df_v0[\"police_report_available\"].transform(fill_na_mean)\n",
    "\n",
    "\n",
    "#CODIFICAMOS CON ORDINAL ENCODER\n",
    "codificar = [\"collision_type_TOUNKNOWNIMP\",\"property_damage_TOUNKNOWNIMP\",\"police_report_available_TOUNKNOWNIMP\",\"incident_hour_of_the_day_TOPARTOFTHEDAY\"]\n",
    "for columnas in codificar:\n",
    "    oe = OrdinalEncoder()\n",
    "    df_v01[columnas] = oe.fit_transform(df_v01[[columnas]])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1c7d10",
   "metadata": {},
   "source": [
    "## PASO 3 CODIFICACION DE LAS VARIABLES (df_v03) DEL DATASET ORIGINAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f07525d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n",
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n",
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n",
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n",
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n",
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n",
      "C:\\Users\\danny\\anaconda3\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1037: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=4.\n",
      "  \"KMeans is known to have a memory leak on Windows \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_sex</th>\n",
       "      <th>insured_education_level</th>\n",
       "      <th>insured_occupation</th>\n",
       "      <th>...</th>\n",
       "      <th>witnesses</th>\n",
       "      <th>police_report_available</th>\n",
       "      <th>total_claim_amount</th>\n",
       "      <th>injury_claim</th>\n",
       "      <th>property_claim</th>\n",
       "      <th>vehicle_claim</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "      <th>fraud_reported</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>285</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>130</td>\n",
       "      <td>34</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>456</td>\n",
       "      <td>60</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     months_as_customer  age  policy_state  policy_csl  policy_deductable  \\\n",
       "0                   328   48           2.0         1.0                1.0   \n",
       "1                   228   42           1.0         1.0                2.0   \n",
       "2                   134   29           2.0         0.0                2.0   \n",
       "3                   256   41           0.0         1.0                2.0   \n",
       "4                   228   44           0.0         2.0                1.0   \n",
       "..                  ...  ...           ...         ...                ...   \n",
       "995                   3   38           2.0         2.0                1.0   \n",
       "996                 285   41           0.0         0.0                1.0   \n",
       "997                 130   34           2.0         1.0                0.0   \n",
       "998                 458   62           0.0         2.0                2.0   \n",
       "999                 456   60           2.0         1.0                1.0   \n",
       "\n",
       "     policy_annual_premium  umbrella_limit  insured_sex  \\\n",
       "0                      3.0             1.0          1.0   \n",
       "1                      2.0             5.0          1.0   \n",
       "2                      3.0             5.0          0.0   \n",
       "3                      3.0             6.0          0.0   \n",
       "4                      4.0             6.0          1.0   \n",
       "..                     ...             ...          ...   \n",
       "995                    3.0             1.0          0.0   \n",
       "996                    4.0             1.0          0.0   \n",
       "997                    3.0             3.0          0.0   \n",
       "998                    3.0             5.0          1.0   \n",
       "999                    0.0             1.0          0.0   \n",
       "\n",
       "     insured_education_level  insured_occupation  ...  witnesses  \\\n",
       "0                        4.0                 2.0  ...          2   \n",
       "1                        4.0                 6.0  ...          0   \n",
       "2                        6.0                11.0  ...          3   \n",
       "3                        6.0                 1.0  ...          2   \n",
       "4                        0.0                11.0  ...          1   \n",
       "..                       ...                 ...  ...        ...   \n",
       "995                      5.0                 2.0  ...          1   \n",
       "996                      6.0                 9.0  ...          3   \n",
       "997                      5.0                 1.0  ...          3   \n",
       "998                      0.0                 5.0  ...          1   \n",
       "999                      0.0                11.0  ...          3   \n",
       "\n",
       "     police_report_available  total_claim_amount  injury_claim  \\\n",
       "0                        1.0                 4.0           2.0   \n",
       "1                        0.0                 0.0           0.0   \n",
       "2                        0.0                 1.0           2.0   \n",
       "3                        0.0                 3.0           2.0   \n",
       "4                        0.0                 0.0           0.0   \n",
       "..                       ...                 ...           ...   \n",
       "995                      0.0                 5.0           5.0   \n",
       "996                      0.0                 5.0           5.0   \n",
       "997                      1.0                 3.0           2.0   \n",
       "998                      1.0                 2.0           1.0   \n",
       "999                      0.0                 0.0           0.0   \n",
       "\n",
       "     property_claim  vehicle_claim  auto_make  auto_model  auto_year  \\\n",
       "0               4.0            4.0       10.0         1.0        9.0   \n",
       "1               0.0            0.0        8.0        12.0       12.0   \n",
       "2               1.0            1.0        4.0        30.0       12.0   \n",
       "3               2.0            3.0        3.0        34.0       19.0   \n",
       "4               0.0            0.0        0.0        31.0       14.0   \n",
       "..              ...            ...        ...         ...        ...   \n",
       "995             2.0            4.0        6.0         6.0       11.0   \n",
       "996             5.0            5.0       13.0        28.0       20.0   \n",
       "997             2.0            4.0       11.0        19.0        1.0   \n",
       "998             1.0            2.0        1.0         5.0        3.0   \n",
       "999             0.0            0.0        8.0        12.0       12.0   \n",
       "\n",
       "     fraud_reported  \n",
       "0               1.0  \n",
       "1               1.0  \n",
       "2               0.0  \n",
       "3               1.0  \n",
       "4               0.0  \n",
       "..              ...  \n",
       "995             0.0  \n",
       "996             0.0  \n",
       "997             0.0  \n",
       "998             0.0  \n",
       "999             0.0  \n",
       "\n",
       "[1000 rows x 34 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import KBinsDiscretizer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import Normalizer\n",
    "df_v03 = df_v0.copy()\n",
    "\n",
    "#DEBIDO A QUE EL COLUMNTRANSFORMER NOS DESCOMPONE EL DATAFRAME,\n",
    "#PROCEDEMOS AL PREPROCESADO MANUAL DE LAS COLUMNAS\n",
    "\n",
    "#COLUMNAS DE VALORES CONTÍNUOS A DISCRETIZAR\n",
    "discretizar = [\"vehicle_claim\",\"property_claim\",\"injury_claim\",\n",
    "               \"total_claim_amount\",\"capital-loss\",\n",
    "               \"capital-gains\",\"policy_annual_premium\"]\n",
    "for columnas in discretizar:\n",
    "    kb = KBinsDiscretizer(n_bins=6, encode='ordinal', strategy='kmeans')\n",
    "    df_v03[columnas] = kb.fit_transform(df_v03[[columnas]])\n",
    "\n",
    "#COLUMNAS DE VALORES CATEGÓRICOS A ETIQUETAR NUMERICAMENTE    \n",
    "listaOE = ['auto_year',\"auto_model\",\"auto_make\",\"insured_relationship\",\n",
    "       \"insured_hobbies\",\"insured_occupation\",\"insured_education_level\",\n",
    "          \"incident_city\",\"incident_state\",\"authorities_contacted\",\"incident_severity\",\n",
    "           \"collision_type\",\"incident_type\",\"insured_sex\",\"umbrella_limit\",\"policy_deductable\",\n",
    "          \"policy_csl\",\"policy_state\",\"police_report_available\", \"property_damage\",\"fraud_reported\"]\n",
    "\n",
    "for columnas in listaOE:\n",
    "    oe = OrdinalEncoder()\n",
    "    df_v03[columnas] = oe.fit_transform(df_v03[[columnas]])\n",
    "\n",
    "#COLUMNAS DE CON VALORES A IMPUTAR (MODA) \n",
    "imputar = ['collision_type',\"property_damage\",\"police_report_available\"]\n",
    "for columnas in listaOE:\n",
    "    si = SimpleImputer(strategy=\"most_frequent\")\n",
    "    df_v03[columnas] = si.fit_transform(df_v03[[columnas]])\n",
    "    \n",
    "#COLUMNAS A ELIMINAR\n",
    "eliminar = [\"policy_number\",\"incident_date\",\"policy_bind_date\",\"insured_zip\",\"incident_location\"]\n",
    "for columnas in eliminar:\n",
    "    df_v03.drop(columnas, axis=1, inplace=True)\n",
    "    \n",
    "df_v03"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd623ee5",
   "metadata": {},
   "source": [
    "## SUMA DE LAS VARIABLES CREADAS Y LAS EXISTENTES (df_v04)\n",
    "### (HAY VARIABLES QUE TIENEN DOBLE REPRESENTACIÓN: VARIABLE ORIGINAL Y TRANSFORMADA) \n",
    "## SEPARACIÓN VARIABLE DEPENDIENTE DE LAS INDEPENDIENTES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "353ed6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "df_v04 = pd.concat([df_v01,df_v03],axis=1)\n",
    "\n",
    "#SEPARAMOS VARIABLES DEPENDIENTE E INDEPENDIENTES\n",
    "y_df = df_v04[\"fraud_reported\"]\n",
    "X_df_v1 = df_v04.copy()\n",
    "X_df_v1.drop(columns=['fraud_reported',], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d2340a",
   "metadata": {},
   "source": [
    "## PASO 4 EN EL SIGUIENTE PASO CREO UNA SERIE DE MÉTODOS PARA REALIZAR UN ONE HOT ENCODING SIN CARGARME EL DATASET Y APLICARLO A TODAS LAS VARIABLES CON 10 CATEGORÍAS O MENOS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3cab0c4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age_TOAGEGROUP_10</th>\n",
       "      <th>age_TOAGEGROUP_11</th>\n",
       "      <th>age_TOAGEGROUP_12</th>\n",
       "      <th>age_TOAGEGROUP_3</th>\n",
       "      <th>age_TOAGEGROUP_4</th>\n",
       "      <th>age_TOAGEGROUP_5</th>\n",
       "      <th>age_TOAGEGROUP_6</th>\n",
       "      <th>age_TOAGEGROUP_7</th>\n",
       "      <th>age_TOAGEGROUP_8</th>\n",
       "      <th>age_TOAGEGROUP_9</th>\n",
       "      <th>...</th>\n",
       "      <th>months_as_customer_TOYEAR</th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_occupation</th>\n",
       "      <th>insured_hobbies</th>\n",
       "      <th>incident_hour_of_the_day</th>\n",
       "      <th>auto_make</th>\n",
       "      <th>auto_model</th>\n",
       "      <th>auto_year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>27</td>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>5</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>8</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>4.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>21</td>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19</td>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>38</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>20</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>23</td>\n",
       "      <td>285</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23</td>\n",
       "      <td>13.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>130</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>458</td>\n",
       "      <td>62</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>38</td>\n",
       "      <td>456</td>\n",
       "      <td>60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age_TOAGEGROUP_10  age_TOAGEGROUP_11  age_TOAGEGROUP_12  \\\n",
       "0                    0                  0                  0   \n",
       "1                    0                  0                  0   \n",
       "2                    0                  0                  0   \n",
       "3                    0                  0                  0   \n",
       "4                    0                  0                  0   \n",
       "..                 ...                ...                ...   \n",
       "995                  0                  0                  0   \n",
       "996                  0                  0                  0   \n",
       "997                  0                  0                  0   \n",
       "998                  0                  0                  1   \n",
       "999                  0                  0                  1   \n",
       "\n",
       "     age_TOAGEGROUP_3  age_TOAGEGROUP_4  age_TOAGEGROUP_5  age_TOAGEGROUP_6  \\\n",
       "0                   0                 0                 0                 0   \n",
       "1                   0                 0                 0                 0   \n",
       "2                   0                 0                 1                 0   \n",
       "3                   0                 0                 0                 0   \n",
       "4                   0                 0                 0                 0   \n",
       "..                ...               ...               ...               ...   \n",
       "995                 0                 0                 0                 0   \n",
       "996                 0                 0                 0                 0   \n",
       "997                 0                 0                 0                 1   \n",
       "998                 0                 0                 0                 0   \n",
       "999                 0                 0                 0                 0   \n",
       "\n",
       "     age_TOAGEGROUP_7  age_TOAGEGROUP_8  age_TOAGEGROUP_9  ...  \\\n",
       "0                   0                 0                 1  ...   \n",
       "1                   0                 1                 0  ...   \n",
       "2                   0                 0                 0  ...   \n",
       "3                   0                 1                 0  ...   \n",
       "4                   0                 1                 0  ...   \n",
       "..                ...               ...               ...  ...   \n",
       "995                 1                 0                 0  ...   \n",
       "996                 0                 1                 0  ...   \n",
       "997                 0                 0                 0  ...   \n",
       "998                 0                 0                 0  ...   \n",
       "999                 0                 0                 0  ...   \n",
       "\n",
       "     months_as_customer_TOYEAR  months_as_customer  age  umbrella_limit  \\\n",
       "0                           27                 328   48             1.0   \n",
       "1                           19                 228   42             5.0   \n",
       "2                           11                 134   29             5.0   \n",
       "3                           21                 256   41             6.0   \n",
       "4                           19                 228   44             6.0   \n",
       "..                         ...                 ...  ...             ...   \n",
       "995                          0                   3   38             1.0   \n",
       "996                         23                 285   41             1.0   \n",
       "997                         10                 130   34             3.0   \n",
       "998                         38                 458   62             5.0   \n",
       "999                         38                 456   60             1.0   \n",
       "\n",
       "     insured_occupation  insured_hobbies  incident_hour_of_the_day  auto_make  \\\n",
       "0                   2.0             17.0                         5       10.0   \n",
       "1                   6.0             15.0                         8        8.0   \n",
       "2                  11.0              2.0                         7        4.0   \n",
       "3                   1.0              2.0                         5        3.0   \n",
       "4                  11.0              2.0                        20        0.0   \n",
       "..                  ...              ...                       ...        ...   \n",
       "995                 2.0             13.0                        20        6.0   \n",
       "996                 9.0             17.0                        23       13.0   \n",
       "997                 1.0              3.0                         4       11.0   \n",
       "998                 5.0              0.0                         2        1.0   \n",
       "999                11.0             11.0                         6        8.0   \n",
       "\n",
       "     auto_model  auto_year  \n",
       "0           1.0        9.0  \n",
       "1          12.0       12.0  \n",
       "2          30.0       12.0  \n",
       "3          34.0       19.0  \n",
       "4          31.0       14.0  \n",
       "..          ...        ...  \n",
       "995         6.0       11.0  \n",
       "996        28.0       20.0  \n",
       "997        19.0        1.0  \n",
       "998         5.0        3.0  \n",
       "999        12.0       12.0  \n",
       "\n",
       "[1000 rows x 154 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#VAMOS A HACER CREAR UN DATASET ONE_HOT_ENCODER APLICANDO EL ONE_HOT A TODAS LAS CATEGORÍAS QUE \n",
    "#TENGAN MENOS DE 11 CATEGORÍAS\n",
    "X_df_v2 = X_df_v1.copy()\n",
    "\n",
    "\n",
    "#Lista de número de categorías distintas del dataSet original\n",
    "uvs = X_df_v1.nunique().tolist()\n",
    "\n",
    "#Apuntaré en las siguientes dos listas los índices de las columnas de tengan menos y mas/igual de 11 categorías\n",
    "ncol = []\n",
    "ncolinv = []\n",
    "#Con el bucle relleno ambas listas\n",
    "c = 0\n",
    "for i in uvs:\n",
    "    if i<=10:\n",
    "        ncol.append(c)\n",
    "    else:\n",
    "        ncolinv.append(c)\n",
    "    c+=1\n",
    "\n",
    "#DataSet con variables de menos de 11 categorías\n",
    "X_df_v2A=X_df_v2.iloc[:,ncol]\n",
    "\n",
    "#DataSet con variables de mas de 10 categorías\n",
    "X_df_v2B=X_df_v2.iloc[:,ncolinv]\n",
    "    \n",
    "#Defino el ONE_HOT_ENCODER casero que hemos fabricado para no cargarnos el dataframe\n",
    "def createDummies(df, var_name):\n",
    "    dummy =pd.get_dummies(df[var_name])\n",
    "    df=df.drop(var_name,axis=1)\n",
    "    df=pd.concat([df,dummy],axis=1)\n",
    "    return(df)\n",
    "    \n",
    "#Debido a que esta pensado para usarse con objects o strings hago la transformación pertinente\n",
    "listcol = X_df_v2A.columns.tolist()\n",
    "X_df_v2A = X_df_v2A.astype(str)\n",
    "\n",
    "#Aplico el ONE_HOT_ENCODER casero al dataSet de menos de 11 categorías\n",
    "X_df_v2A = createDummies(X_df_v2A, listcol)\n",
    "\n",
    "#Concateno el dataSet que tiene variables con mas de 11 categorías\n",
    "X_df_v3 = pd.concat([X_df_v2A,X_df_v2B], axis = 1)\n",
    "    \n",
    "\n",
    "X_df_v3\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fad1ed98",
   "metadata": {},
   "source": [
    "## PASO 5 FASE DE APLICACIÓN DE MODELO DE DEEP LEARNING"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c93067da",
   "metadata": {},
   "source": [
    "### 5.1 Selección de variables con SelectKBest con el modelo: mutual_info_classif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "a6aa9229",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, mutual_info_classif\n",
    "X_df_3_1 = SelectKBest(mutual_info_classif, k=10).fit_transform(X_df_v3, y_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "25bb05ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec7b68",
   "metadata": {},
   "source": [
    "### 5.2 Separación de variables dependientes e independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b274e97f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_df_3_1, y_df, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69fe5faa",
   "metadata": {},
   "source": [
    "### 5.3 Normalizado de variables dependientes e independientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "cca142b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e24b73d",
   "metadata": {},
   "source": [
    "### 5.4 Modelado del modelo de feed forward neural network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "49b24928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "model = keras.Sequential()\n",
    "\n",
    "num_neuronas = X_train.shape[1]\n",
    "model.add(Dense(units=num_neuronas, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(units = np.round(0.5*num_neuronas), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(units = np.round(0.25*num_neuronas), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# model = keras.Sequential()\n",
    "\n",
    "# num_neuronas = X_train.shape[1]\n",
    "# model.add(Dense(units=num_neuronas, activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(units = np.round(30*num_neuronas), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(units = np.round(30*num_neuronas), activation='relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "# model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# model = keras.Sequential()\n",
    "# model.add(tf.keras.layers.Flatten())\n",
    "# model.add(layers.Dense(128, activation='sigmoid'))\n",
    "# model.add(layers.Dense(128, activation='sigmoid'))\n",
    "# model.add(layers.Dense(1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dc6d86f",
   "metadata": {},
   "source": [
    "### 5.5 Definición de la herramienta EarlyStopping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "85e77cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=200)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9da7a89",
   "metadata": {},
   "source": [
    "### 5.6 Definición de la  función de coste  Adam y compilado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "d7248b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = keras.optimizers.Adam(lr=0.1)\n",
    "model.compile(loss='binary_crossentropy', optimizer = optimizer, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b83e53",
   "metadata": {},
   "source": [
    "### 5.7 Definición de la  función de coste  Adam y compilado del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "7303e0af",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "X_train1 = K.cast_to_floatx(X_train)\n",
    "y_train1 = K.cast_to_floatx(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "8ed4be23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(700, 10)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "52dfa7af",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2 = np.asarray(X_train1)\n",
    "y_train2 = np.asarray(y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013ce004",
   "metadata": {},
   "source": [
    "### 5.8 Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "220342df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 700 samples, validate on 300 samples\n",
      "Epoch 1/3000\n",
      "700/700 [==============================] - 0s 603us/sample - loss: 0.5446 - acc: 0.7614 - val_loss: 0.5437 - val_acc: 0.7333\n",
      "Epoch 2/3000\n",
      "700/700 [==============================] - 0s 158us/sample - loss: 0.5008 - acc: 0.7614 - val_loss: 0.5366 - val_acc: 0.7333\n",
      "Epoch 3/3000\n",
      "700/700 [==============================] - 0s 171us/sample - loss: 0.4815 - acc: 0.7786 - val_loss: 0.4894 - val_acc: 0.8000\n",
      "Epoch 4/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.4607 - acc: 0.7986 - val_loss: 0.5328 - val_acc: 0.7633\n",
      "Epoch 5/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.4392 - acc: 0.7986 - val_loss: 0.4822 - val_acc: 0.8000\n",
      "Epoch 6/3000\n",
      "700/700 [==============================] - 0s 136us/sample - loss: 0.4290 - acc: 0.8100 - val_loss: 0.4745 - val_acc: 0.8000\n",
      "Epoch 7/3000\n",
      "700/700 [==============================] - 0s 139us/sample - loss: 0.4301 - acc: 0.8143 - val_loss: 0.5422 - val_acc: 0.7767\n",
      "Epoch 8/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.4182 - acc: 0.8057 - val_loss: 0.4697 - val_acc: 0.8000\n",
      "Epoch 9/3000\n",
      "700/700 [==============================] - 0s 136us/sample - loss: 0.4318 - acc: 0.8043 - val_loss: 0.4854 - val_acc: 0.7967\n",
      "Epoch 10/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4232 - acc: 0.8086 - val_loss: 0.4770 - val_acc: 0.7833\n",
      "Epoch 11/3000\n",
      "700/700 [==============================] - 0s 144us/sample - loss: 0.4138 - acc: 0.8100 - val_loss: 0.5713 - val_acc: 0.7833\n",
      "Epoch 12/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.4150 - acc: 0.8186 - val_loss: 0.4919 - val_acc: 0.7733\n",
      "Epoch 13/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4195 - acc: 0.8129 - val_loss: 0.5118 - val_acc: 0.7800\n",
      "Epoch 14/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.4118 - acc: 0.8143 - val_loss: 0.4903 - val_acc: 0.7967\n",
      "Epoch 15/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.4194 - acc: 0.8171 - val_loss: 0.5274 - val_acc: 0.7867\n",
      "Epoch 16/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.4233 - acc: 0.8043 - val_loss: 0.4870 - val_acc: 0.7900\n",
      "Epoch 17/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.4513 - acc: 0.7771 - val_loss: 0.5106 - val_acc: 0.7867\n",
      "Epoch 18/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4523 - acc: 0.7729 - val_loss: 0.5814 - val_acc: 0.7800\n",
      "Epoch 19/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4602 - acc: 0.7914 - val_loss: 0.4904 - val_acc: 0.7833\n",
      "Epoch 20/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4314 - acc: 0.8043 - val_loss: 0.6137 - val_acc: 0.7767\n",
      "Epoch 21/3000\n",
      "700/700 [==============================] - 0s 142us/sample - loss: 0.4315 - acc: 0.8214 - val_loss: 0.4833 - val_acc: 0.7933\n",
      "Epoch 22/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4028 - acc: 0.8157 - val_loss: 0.4784 - val_acc: 0.7967\n",
      "Epoch 23/3000\n",
      "700/700 [==============================] - 0s 139us/sample - loss: 0.4116 - acc: 0.8129 - val_loss: 0.4814 - val_acc: 0.7900\n",
      "Epoch 24/3000\n",
      "700/700 [==============================] - 0s 146us/sample - loss: 0.4020 - acc: 0.8143 - val_loss: 0.5012 - val_acc: 0.7900\n",
      "Epoch 25/3000\n",
      "700/700 [==============================] - 0s 136us/sample - loss: 0.4129 - acc: 0.8143 - val_loss: 0.5091 - val_acc: 0.7967\n",
      "Epoch 26/3000\n",
      "700/700 [==============================] - 0s 176us/sample - loss: 0.4104 - acc: 0.8129 - val_loss: 0.4832 - val_acc: 0.7900\n",
      "Epoch 27/3000\n",
      "700/700 [==============================] - 0s 158us/sample - loss: 0.4092 - acc: 0.8129 - val_loss: 0.4904 - val_acc: 0.7900\n",
      "Epoch 28/3000\n",
      "700/700 [==============================] - 0s 164us/sample - loss: 0.4010 - acc: 0.8171 - val_loss: 0.5289 - val_acc: 0.7800\n",
      "Epoch 29/3000\n",
      "700/700 [==============================] - 0s 160us/sample - loss: 0.4052 - acc: 0.8171 - val_loss: 0.5008 - val_acc: 0.7733\n",
      "Epoch 30/3000\n",
      "700/700 [==============================] - 0s 142us/sample - loss: 0.4299 - acc: 0.8143 - val_loss: 0.4787 - val_acc: 0.7900\n",
      "Epoch 31/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4083 - acc: 0.8157 - val_loss: 0.4931 - val_acc: 0.7900\n",
      "Epoch 32/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4068 - acc: 0.8129 - val_loss: 0.4969 - val_acc: 0.7900\n",
      "Epoch 33/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.4032 - acc: 0.8157 - val_loss: 0.4893 - val_acc: 0.7667\n",
      "Epoch 34/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3990 - acc: 0.8129 - val_loss: 0.5015 - val_acc: 0.7633\n",
      "Epoch 35/3000\n",
      "700/700 [==============================] - 0s 150us/sample - loss: 0.4119 - acc: 0.8157 - val_loss: 0.4779 - val_acc: 0.7767\n",
      "Epoch 36/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.4020 - acc: 0.8114 - val_loss: 0.4917 - val_acc: 0.7900\n",
      "Epoch 37/3000\n",
      "700/700 [==============================] - 0s 160us/sample - loss: 0.4043 - acc: 0.8114 - val_loss: 0.4826 - val_acc: 0.7800\n",
      "Epoch 38/3000\n",
      "700/700 [==============================] - 0s 157us/sample - loss: 0.4049 - acc: 0.8143 - val_loss: 0.4892 - val_acc: 0.7733\n",
      "Epoch 39/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4141 - acc: 0.8157 - val_loss: 0.4736 - val_acc: 0.7800\n",
      "Epoch 40/3000\n",
      "700/700 [==============================] - 0s 129us/sample - loss: 0.4128 - acc: 0.8186 - val_loss: 0.4743 - val_acc: 0.7733\n",
      "Epoch 41/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3992 - acc: 0.8143 - val_loss: 0.6135 - val_acc: 0.7733\n",
      "Epoch 42/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4193 - acc: 0.8171 - val_loss: 0.4790 - val_acc: 0.8000\n",
      "Epoch 43/3000\n",
      "700/700 [==============================] - 0s 132us/sample - loss: 0.4108 - acc: 0.8100 - val_loss: 0.4737 - val_acc: 0.7733\n",
      "Epoch 44/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.4293 - acc: 0.8114 - val_loss: 0.5256 - val_acc: 0.7967\n",
      "Epoch 45/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4121 - acc: 0.8157 - val_loss: 0.5131 - val_acc: 0.7967\n",
      "Epoch 46/3000\n",
      "700/700 [==============================] - 0s 144us/sample - loss: 0.3947 - acc: 0.8143 - val_loss: 0.4820 - val_acc: 0.7967\n",
      "Epoch 47/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3967 - acc: 0.8171 - val_loss: 0.4753 - val_acc: 0.7767\n",
      "Epoch 48/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4008 - acc: 0.8200 - val_loss: 0.4872 - val_acc: 0.7700\n",
      "Epoch 49/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4006 - acc: 0.8171 - val_loss: 0.5046 - val_acc: 0.7733\n",
      "Epoch 50/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3951 - acc: 0.8157 - val_loss: 0.5133 - val_acc: 0.7667\n",
      "Epoch 51/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3983 - acc: 0.8129 - val_loss: 0.5831 - val_acc: 0.7533\n",
      "Epoch 52/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4041 - acc: 0.8014 - val_loss: 0.5483 - val_acc: 0.7600\n",
      "Epoch 53/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3974 - acc: 0.8143 - val_loss: 0.5314 - val_acc: 0.7667\n",
      "Epoch 54/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.3979 - acc: 0.8157 - val_loss: 0.5948 - val_acc: 0.7667\n",
      "Epoch 55/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3993 - acc: 0.8100 - val_loss: 0.5542 - val_acc: 0.7367\n",
      "Epoch 56/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3971 - acc: 0.8157 - val_loss: 0.5535 - val_acc: 0.7633\n",
      "Epoch 57/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3934 - acc: 0.8129 - val_loss: 0.6504 - val_acc: 0.7667\n",
      "Epoch 58/3000\n",
      "700/700 [==============================] - 0s 136us/sample - loss: 0.4092 - acc: 0.8129 - val_loss: 0.5339 - val_acc: 0.7633\n",
      "Epoch 59/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4005 - acc: 0.8157 - val_loss: 0.5016 - val_acc: 0.7667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 60/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.4111 - acc: 0.8100 - val_loss: 0.4714 - val_acc: 0.7767\n",
      "Epoch 61/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.4158 - acc: 0.8100 - val_loss: 0.5079 - val_acc: 0.7767\n",
      "Epoch 62/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.4224 - acc: 0.8043 - val_loss: 0.5386 - val_acc: 0.7733\n",
      "Epoch 63/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3994 - acc: 0.8129 - val_loss: 0.4723 - val_acc: 0.7767\n",
      "Epoch 64/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4020 - acc: 0.8114 - val_loss: 0.4858 - val_acc: 0.7800\n",
      "Epoch 65/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3993 - acc: 0.8129 - val_loss: 0.4724 - val_acc: 0.7800\n",
      "Epoch 66/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.4028 - acc: 0.8057 - val_loss: 0.4904 - val_acc: 0.7767\n",
      "Epoch 67/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3998 - acc: 0.8143 - val_loss: 0.5395 - val_acc: 0.7767\n",
      "Epoch 68/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4207 - acc: 0.7829 - val_loss: 0.4686 - val_acc: 0.7933\n",
      "Epoch 69/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4171 - acc: 0.8000 - val_loss: 0.4757 - val_acc: 0.7833\n",
      "Epoch 70/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4234 - acc: 0.8200 - val_loss: 0.5411 - val_acc: 0.7833\n",
      "Epoch 71/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4241 - acc: 0.8043 - val_loss: 0.5146 - val_acc: 0.7867\n",
      "Epoch 72/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4218 - acc: 0.8171 - val_loss: 0.4914 - val_acc: 0.7933\n",
      "Epoch 73/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4082 - acc: 0.8114 - val_loss: 0.4935 - val_acc: 0.7867\n",
      "Epoch 74/3000\n",
      "700/700 [==============================] - 0s 122us/sample - loss: 0.4156 - acc: 0.7986 - val_loss: 0.5395 - val_acc: 0.7767\n",
      "Epoch 75/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4111 - acc: 0.8071 - val_loss: 0.4962 - val_acc: 0.7633\n",
      "Epoch 76/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4161 - acc: 0.8100 - val_loss: 0.4955 - val_acc: 0.7900\n",
      "Epoch 77/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.4238 - acc: 0.8157 - val_loss: 0.4952 - val_acc: 0.7867\n",
      "Epoch 78/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4515 - acc: 0.7771 - val_loss: 0.5561 - val_acc: 0.7333\n",
      "Epoch 79/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.4078 - acc: 0.7814 - val_loss: 0.4778 - val_acc: 0.7800\n",
      "Epoch 80/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4084 - acc: 0.8143 - val_loss: 0.4936 - val_acc: 0.7533\n",
      "Epoch 81/3000\n",
      "700/700 [==============================] - 0s 141us/sample - loss: 0.4042 - acc: 0.8114 - val_loss: 0.4986 - val_acc: 0.7733\n",
      "Epoch 82/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4088 - acc: 0.8129 - val_loss: 0.4640 - val_acc: 0.7800\n",
      "Epoch 83/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4408 - acc: 0.7443 - val_loss: 0.5670 - val_acc: 0.7333\n",
      "Epoch 84/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4210 - acc: 0.7643 - val_loss: 0.5475 - val_acc: 0.7500\n",
      "Epoch 85/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4122 - acc: 0.8071 - val_loss: 0.4989 - val_acc: 0.7900\n",
      "Epoch 86/3000\n",
      "700/700 [==============================] - 0s 144us/sample - loss: 0.4157 - acc: 0.8157 - val_loss: 0.4962 - val_acc: 0.7833\n",
      "Epoch 87/3000\n",
      "700/700 [==============================] - 0s 157us/sample - loss: 0.4091 - acc: 0.8143 - val_loss: 0.5335 - val_acc: 0.7900\n",
      "Epoch 88/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4161 - acc: 0.8157 - val_loss: 0.4970 - val_acc: 0.7900\n",
      "Epoch 89/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4159 - acc: 0.8143 - val_loss: 0.5131 - val_acc: 0.7867\n",
      "Epoch 90/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4053 - acc: 0.8143 - val_loss: 0.5658 - val_acc: 0.7833\n",
      "Epoch 91/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.3898 - acc: 0.8200 - val_loss: 0.5894 - val_acc: 0.7900\n",
      "Epoch 92/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3988 - acc: 0.8171 - val_loss: 0.5399 - val_acc: 0.7900\n",
      "Epoch 93/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3983 - acc: 0.8186 - val_loss: 0.5197 - val_acc: 0.7867\n",
      "Epoch 94/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.3996 - acc: 0.8143 - val_loss: 0.5346 - val_acc: 0.7900\n",
      "Epoch 95/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4296 - acc: 0.8114 - val_loss: 0.5543 - val_acc: 0.7900\n",
      "Epoch 96/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4132 - acc: 0.8129 - val_loss: 0.5538 - val_acc: 0.7900\n",
      "Epoch 97/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4043 - acc: 0.8129 - val_loss: 0.4955 - val_acc: 0.7967\n",
      "Epoch 98/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.4002 - acc: 0.8171 - val_loss: 0.4788 - val_acc: 0.7967\n",
      "Epoch 99/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3948 - acc: 0.8171 - val_loss: 0.5224 - val_acc: 0.7967\n",
      "Epoch 100/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.4127 - acc: 0.8071 - val_loss: 0.4806 - val_acc: 0.7867\n",
      "Epoch 101/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.4120 - acc: 0.7914 - val_loss: 0.4960 - val_acc: 0.7533\n",
      "Epoch 102/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.4087 - acc: 0.7843 - val_loss: 0.5005 - val_acc: 0.7700\n",
      "Epoch 103/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.4136 - acc: 0.8057 - val_loss: 0.6207 - val_acc: 0.7467\n",
      "Epoch 104/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.4295 - acc: 0.8129 - val_loss: 0.4810 - val_acc: 0.7767\n",
      "Epoch 105/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.3982 - acc: 0.8157 - val_loss: 0.4837 - val_acc: 0.7700\n",
      "Epoch 106/3000\n",
      "700/700 [==============================] - 0s 141us/sample - loss: 0.3970 - acc: 0.8143 - val_loss: 0.4988 - val_acc: 0.7733\n",
      "Epoch 107/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3991 - acc: 0.8157 - val_loss: 0.5490 - val_acc: 0.7733\n",
      "Epoch 108/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4018 - acc: 0.8129 - val_loss: 0.4906 - val_acc: 0.7700\n",
      "Epoch 109/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.4020 - acc: 0.8100 - val_loss: 0.5139 - val_acc: 0.7767\n",
      "Epoch 110/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3913 - acc: 0.8143 - val_loss: 0.4799 - val_acc: 0.7733\n",
      "Epoch 111/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.4071 - acc: 0.8171 - val_loss: 0.5405 - val_acc: 0.7700\n",
      "Epoch 112/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3960 - acc: 0.8171 - val_loss: 0.5060 - val_acc: 0.7700\n",
      "Epoch 113/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3950 - acc: 0.8186 - val_loss: 0.5147 - val_acc: 0.7733\n",
      "Epoch 114/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4035 - acc: 0.8086 - val_loss: 0.5552 - val_acc: 0.7700\n",
      "Epoch 115/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4028 - acc: 0.8129 - val_loss: 0.5328 - val_acc: 0.7700\n",
      "Epoch 116/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3941 - acc: 0.8157 - val_loss: 0.5900 - val_acc: 0.7667\n",
      "Epoch 117/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.3982 - acc: 0.8171 - val_loss: 0.4860 - val_acc: 0.7633\n",
      "Epoch 118/3000\n",
      "700/700 [==============================] - 0s 145us/sample - loss: 0.4107 - acc: 0.8143 - val_loss: 0.4806 - val_acc: 0.7700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 119/3000\n",
      "700/700 [==============================] - 0s 132us/sample - loss: 0.4130 - acc: 0.8129 - val_loss: 0.5658 - val_acc: 0.7733\n",
      "Epoch 120/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.4116 - acc: 0.8157 - val_loss: 0.5169 - val_acc: 0.7700\n",
      "Epoch 121/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.4008 - acc: 0.8100 - val_loss: 0.5207 - val_acc: 0.7800\n",
      "Epoch 122/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4123 - acc: 0.7986 - val_loss: 0.4993 - val_acc: 0.7367\n",
      "Epoch 123/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4039 - acc: 0.8071 - val_loss: 0.4775 - val_acc: 0.7867\n",
      "Epoch 124/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4022 - acc: 0.8186 - val_loss: 0.5045 - val_acc: 0.7767\n",
      "Epoch 125/3000\n",
      "700/700 [==============================] - 0s 122us/sample - loss: 0.4045 - acc: 0.8071 - val_loss: 0.5185 - val_acc: 0.7800\n",
      "Epoch 126/3000\n",
      "700/700 [==============================] - 0s 129us/sample - loss: 0.4051 - acc: 0.8129 - val_loss: 0.5195 - val_acc: 0.7600\n",
      "Epoch 127/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3984 - acc: 0.8171 - val_loss: 0.5050 - val_acc: 0.7900\n",
      "Epoch 128/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4006 - acc: 0.8200 - val_loss: 0.5348 - val_acc: 0.7900\n",
      "Epoch 129/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.3896 - acc: 0.8171 - val_loss: 0.5098 - val_acc: 0.7900\n",
      "Epoch 130/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3913 - acc: 0.8171 - val_loss: 0.5181 - val_acc: 0.7900\n",
      "Epoch 131/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3922 - acc: 0.8200 - val_loss: 0.4752 - val_acc: 0.7900\n",
      "Epoch 132/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4034 - acc: 0.8143 - val_loss: 0.4873 - val_acc: 0.7933\n",
      "Epoch 133/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3995 - acc: 0.8114 - val_loss: 0.4792 - val_acc: 0.7933\n",
      "Epoch 134/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4047 - acc: 0.8171 - val_loss: 0.4664 - val_acc: 0.7967\n",
      "Epoch 135/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4042 - acc: 0.8157 - val_loss: 0.5596 - val_acc: 0.7900\n",
      "Epoch 136/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3876 - acc: 0.8129 - val_loss: 0.5545 - val_acc: 0.7833\n",
      "Epoch 137/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.4065 - acc: 0.8171 - val_loss: 0.5858 - val_acc: 0.7833\n",
      "Epoch 138/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.3977 - acc: 0.8200 - val_loss: 0.4905 - val_acc: 0.7700\n",
      "Epoch 139/3000\n",
      "700/700 [==============================] - 0s 152us/sample - loss: 0.4126 - acc: 0.8186 - val_loss: 0.5008 - val_acc: 0.7900\n",
      "Epoch 140/3000\n",
      "700/700 [==============================] - 0s 167us/sample - loss: 0.3902 - acc: 0.8171 - val_loss: 0.5063 - val_acc: 0.7833\n",
      "Epoch 141/3000\n",
      "700/700 [==============================] - 0s 174us/sample - loss: 0.3900 - acc: 0.8200 - val_loss: 0.5689 - val_acc: 0.7900\n",
      "Epoch 142/3000\n",
      "700/700 [==============================] - 0s 147us/sample - loss: 0.3963 - acc: 0.8200 - val_loss: 0.5699 - val_acc: 0.7833\n",
      "Epoch 143/3000\n",
      "700/700 [==============================] - 0s 146us/sample - loss: 0.3843 - acc: 0.8186 - val_loss: 0.5064 - val_acc: 0.7767\n",
      "Epoch 144/3000\n",
      "700/700 [==============================] - 0s 162us/sample - loss: 0.3943 - acc: 0.8114 - val_loss: 0.5375 - val_acc: 0.7900\n",
      "Epoch 145/3000\n",
      "700/700 [==============================] - 0s 160us/sample - loss: 0.3892 - acc: 0.8200 - val_loss: 0.5083 - val_acc: 0.7867\n",
      "Epoch 146/3000\n",
      "700/700 [==============================] - 0s 157us/sample - loss: 0.3887 - acc: 0.8171 - val_loss: 0.5411 - val_acc: 0.7900\n",
      "Epoch 147/3000\n",
      "700/700 [==============================] - 0s 142us/sample - loss: 0.3823 - acc: 0.8200 - val_loss: 0.5280 - val_acc: 0.7733\n",
      "Epoch 148/3000\n",
      "700/700 [==============================] - 0s 142us/sample - loss: 0.3939 - acc: 0.8229 - val_loss: 0.5154 - val_acc: 0.7767\n",
      "Epoch 149/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.3943 - acc: 0.8157 - val_loss: 0.4776 - val_acc: 0.7933\n",
      "Epoch 150/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3824 - acc: 0.8171 - val_loss: 0.5086 - val_acc: 0.7933\n",
      "Epoch 151/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3965 - acc: 0.8171 - val_loss: 0.4836 - val_acc: 0.7733\n",
      "Epoch 152/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.3876 - acc: 0.8171 - val_loss: 0.4897 - val_acc: 0.7833\n",
      "Epoch 153/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4034 - acc: 0.8171 - val_loss: 0.5425 - val_acc: 0.7933\n",
      "Epoch 154/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3891 - acc: 0.8129 - val_loss: 0.4871 - val_acc: 0.7700\n",
      "Epoch 155/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3878 - acc: 0.8186 - val_loss: 0.4922 - val_acc: 0.7867\n",
      "Epoch 156/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3839 - acc: 0.8143 - val_loss: 0.4896 - val_acc: 0.7867\n",
      "Epoch 157/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.3944 - acc: 0.8157 - val_loss: 0.5272 - val_acc: 0.7967\n",
      "Epoch 158/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3922 - acc: 0.8143 - val_loss: 0.5065 - val_acc: 0.7600\n",
      "Epoch 159/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.3874 - acc: 0.8157 - val_loss: 0.5047 - val_acc: 0.7867\n",
      "Epoch 160/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.3812 - acc: 0.8229 - val_loss: 0.5648 - val_acc: 0.7867\n",
      "Epoch 161/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.4005 - acc: 0.8200 - val_loss: 0.4932 - val_acc: 0.7933\n",
      "Epoch 162/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.3896 - acc: 0.8214 - val_loss: 0.5241 - val_acc: 0.7867\n",
      "Epoch 163/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3990 - acc: 0.8186 - val_loss: 0.5025 - val_acc: 0.7833\n",
      "Epoch 164/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3858 - acc: 0.8057 - val_loss: 0.5896 - val_acc: 0.7833\n",
      "Epoch 165/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3914 - acc: 0.8200 - val_loss: 0.5325 - val_acc: 0.7733\n",
      "Epoch 166/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3883 - acc: 0.8143 - val_loss: 0.5378 - val_acc: 0.7667\n",
      "Epoch 167/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3916 - acc: 0.8171 - val_loss: 0.5946 - val_acc: 0.7800\n",
      "Epoch 168/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4115 - acc: 0.8171 - val_loss: 0.5041 - val_acc: 0.7800\n",
      "Epoch 169/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3892 - acc: 0.8186 - val_loss: 0.6294 - val_acc: 0.7900\n",
      "Epoch 170/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4078 - acc: 0.8100 - val_loss: 0.5172 - val_acc: 0.7833\n",
      "Epoch 171/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3888 - acc: 0.8186 - val_loss: 0.4988 - val_acc: 0.7867\n",
      "Epoch 172/3000\n",
      "700/700 [==============================] - 0s 158us/sample - loss: 0.3878 - acc: 0.8157 - val_loss: 0.4993 - val_acc: 0.7800\n",
      "Epoch 173/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.4029 - acc: 0.8200 - val_loss: 0.5433 - val_acc: 0.7833\n",
      "Epoch 174/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3814 - acc: 0.8186 - val_loss: 0.4957 - val_acc: 0.7800\n",
      "Epoch 175/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3875 - acc: 0.8200 - val_loss: 0.5317 - val_acc: 0.7767\n",
      "Epoch 176/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3788 - acc: 0.8143 - val_loss: 0.6118 - val_acc: 0.7733\n",
      "Epoch 177/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 139us/sample - loss: 0.3899 - acc: 0.8129 - val_loss: 0.5503 - val_acc: 0.7533\n",
      "Epoch 178/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3950 - acc: 0.8171 - val_loss: 0.5553 - val_acc: 0.7667\n",
      "Epoch 179/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3902 - acc: 0.8143 - val_loss: 0.5534 - val_acc: 0.7467\n",
      "Epoch 180/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4233 - acc: 0.8200 - val_loss: 0.4955 - val_acc: 0.7933\n",
      "Epoch 181/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.4325 - acc: 0.7429 - val_loss: 0.5565 - val_acc: 0.7333\n",
      "Epoch 182/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3995 - acc: 0.7943 - val_loss: 0.4892 - val_acc: 0.7867\n",
      "Epoch 183/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.3929 - acc: 0.8129 - val_loss: 0.5823 - val_acc: 0.7800\n",
      "Epoch 184/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4094 - acc: 0.8114 - val_loss: 0.5243 - val_acc: 0.7833\n",
      "Epoch 185/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3929 - acc: 0.8100 - val_loss: 0.4784 - val_acc: 0.7833\n",
      "Epoch 186/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3904 - acc: 0.8114 - val_loss: 0.4853 - val_acc: 0.7767\n",
      "Epoch 187/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3867 - acc: 0.8200 - val_loss: 0.4974 - val_acc: 0.7800\n",
      "Epoch 188/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3918 - acc: 0.8157 - val_loss: 0.4838 - val_acc: 0.7800\n",
      "Epoch 189/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.4043 - acc: 0.8100 - val_loss: 0.4858 - val_acc: 0.7800\n",
      "Epoch 190/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3938 - acc: 0.8200 - val_loss: 0.5283 - val_acc: 0.7767\n",
      "Epoch 191/3000\n",
      "700/700 [==============================] - 0s 141us/sample - loss: 0.3945 - acc: 0.8186 - val_loss: 0.5490 - val_acc: 0.7800\n",
      "Epoch 192/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3835 - acc: 0.8186 - val_loss: 0.5052 - val_acc: 0.7767\n",
      "Epoch 193/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3809 - acc: 0.8171 - val_loss: 0.5120 - val_acc: 0.7800\n",
      "Epoch 194/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3931 - acc: 0.8186 - val_loss: 0.5488 - val_acc: 0.7767\n",
      "Epoch 195/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4043 - acc: 0.8143 - val_loss: 0.5023 - val_acc: 0.7733\n",
      "Epoch 196/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3793 - acc: 0.8200 - val_loss: 0.5083 - val_acc: 0.7800\n",
      "Epoch 197/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.3821 - acc: 0.8214 - val_loss: 0.5713 - val_acc: 0.7767\n",
      "Epoch 198/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.3882 - acc: 0.8171 - val_loss: 0.4974 - val_acc: 0.7667\n",
      "Epoch 199/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.3840 - acc: 0.8200 - val_loss: 0.5151 - val_acc: 0.7633\n",
      "Epoch 200/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3844 - acc: 0.8186 - val_loss: 0.6260 - val_acc: 0.7767\n",
      "Epoch 201/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4126 - acc: 0.7986 - val_loss: 0.7380 - val_acc: 0.7600\n",
      "Epoch 202/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4283 - acc: 0.7900 - val_loss: 0.6019 - val_acc: 0.7567\n",
      "Epoch 203/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4086 - acc: 0.7771 - val_loss: 0.5805 - val_acc: 0.7433\n",
      "Epoch 204/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4092 - acc: 0.7714 - val_loss: 0.5794 - val_acc: 0.7100\n",
      "Epoch 205/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.4136 - acc: 0.7657 - val_loss: 0.5703 - val_acc: 0.7500\n",
      "Epoch 206/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4200 - acc: 0.7943 - val_loss: 0.5963 - val_acc: 0.7667\n",
      "Epoch 207/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.4117 - acc: 0.7757 - val_loss: 0.5153 - val_acc: 0.7700\n",
      "Epoch 208/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4118 - acc: 0.8000 - val_loss: 0.5091 - val_acc: 0.7567\n",
      "Epoch 209/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.4034 - acc: 0.8100 - val_loss: 0.5081 - val_acc: 0.7933\n",
      "Epoch 210/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.4107 - acc: 0.8029 - val_loss: 0.4930 - val_acc: 0.7967\n",
      "Epoch 211/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3998 - acc: 0.7929 - val_loss: 0.4936 - val_acc: 0.7900\n",
      "Epoch 212/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4025 - acc: 0.8129 - val_loss: 0.5783 - val_acc: 0.7833\n",
      "Epoch 213/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.4113 - acc: 0.8186 - val_loss: 0.5132 - val_acc: 0.7767\n",
      "Epoch 214/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3874 - acc: 0.8186 - val_loss: 0.5267 - val_acc: 0.7867\n",
      "Epoch 215/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3863 - acc: 0.8171 - val_loss: 0.5643 - val_acc: 0.7800\n",
      "Epoch 216/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3951 - acc: 0.8143 - val_loss: 0.5243 - val_acc: 0.7933\n",
      "Epoch 217/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.3944 - acc: 0.8129 - val_loss: 0.4800 - val_acc: 0.7900\n",
      "Epoch 218/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.4041 - acc: 0.8157 - val_loss: 0.4905 - val_acc: 0.7900\n",
      "Epoch 219/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.3987 - acc: 0.8100 - val_loss: 0.5249 - val_acc: 0.7933\n",
      "Epoch 220/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3918 - acc: 0.8129 - val_loss: 0.4881 - val_acc: 0.7867\n",
      "Epoch 221/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3874 - acc: 0.8157 - val_loss: 0.5109 - val_acc: 0.7867\n",
      "Epoch 222/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.3956 - acc: 0.8171 - val_loss: 0.5411 - val_acc: 0.7867\n",
      "Epoch 223/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.4036 - acc: 0.8157 - val_loss: 0.6645 - val_acc: 0.7900\n",
      "Epoch 224/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.4163 - acc: 0.7714 - val_loss: 0.5194 - val_acc: 0.7933\n",
      "Epoch 225/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3843 - acc: 0.8100 - val_loss: 0.5763 - val_acc: 0.7900\n",
      "Epoch 226/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.4057 - acc: 0.8014 - val_loss: 0.5315 - val_acc: 0.7500\n",
      "Epoch 227/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.3969 - acc: 0.8086 - val_loss: 0.5281 - val_acc: 0.7900\n",
      "Epoch 228/3000\n",
      "700/700 [==============================] - 0s 138us/sample - loss: 0.3876 - acc: 0.8129 - val_loss: 0.5308 - val_acc: 0.7900\n",
      "Epoch 229/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.3856 - acc: 0.8143 - val_loss: 0.5433 - val_acc: 0.7833\n",
      "Epoch 230/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3878 - acc: 0.8129 - val_loss: 0.5657 - val_acc: 0.7867\n",
      "Epoch 231/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4055 - acc: 0.8114 - val_loss: 0.5527 - val_acc: 0.7767\n",
      "Epoch 232/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3980 - acc: 0.8157 - val_loss: 0.4996 - val_acc: 0.7900\n",
      "Epoch 233/3000\n",
      "700/700 [==============================] - 0s 139us/sample - loss: 0.3867 - acc: 0.8143 - val_loss: 0.5525 - val_acc: 0.7833\n",
      "Epoch 234/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.4072 - acc: 0.8129 - val_loss: 0.5519 - val_acc: 0.7800\n",
      "Epoch 235/3000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3905 - acc: 0.8143 - val_loss: 0.4719 - val_acc: 0.7900\n",
      "Epoch 236/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3801 - acc: 0.8171 - val_loss: 0.5721 - val_acc: 0.7833\n",
      "Epoch 237/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3820 - acc: 0.8143 - val_loss: 0.6705 - val_acc: 0.7800\n",
      "Epoch 238/3000\n",
      "700/700 [==============================] - 0s 137us/sample - loss: 0.3924 - acc: 0.8143 - val_loss: 0.6386 - val_acc: 0.7767\n",
      "Epoch 239/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3799 - acc: 0.8171 - val_loss: 0.5820 - val_acc: 0.7800\n",
      "Epoch 240/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3885 - acc: 0.8129 - val_loss: 0.6354 - val_acc: 0.7800\n",
      "Epoch 241/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3803 - acc: 0.8186 - val_loss: 0.6452 - val_acc: 0.7767\n",
      "Epoch 242/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3834 - acc: 0.8200 - val_loss: 0.7057 - val_acc: 0.7800\n",
      "Epoch 243/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3748 - acc: 0.8200 - val_loss: 0.6075 - val_acc: 0.7733\n",
      "Epoch 244/3000\n",
      "700/700 [==============================] - 0s 136us/sample - loss: 0.3791 - acc: 0.8114 - val_loss: 0.7503 - val_acc: 0.7800\n",
      "Epoch 245/3000\n",
      "700/700 [==============================] - 0s 140us/sample - loss: 0.3970 - acc: 0.7986 - val_loss: 0.7949 - val_acc: 0.7833\n",
      "Epoch 246/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4059 - acc: 0.8157 - val_loss: 0.5765 - val_acc: 0.7733\n",
      "Epoch 247/3000\n",
      "700/700 [==============================] - 0s 121us/sample - loss: 0.3926 - acc: 0.8114 - val_loss: 0.6209 - val_acc: 0.7733\n",
      "Epoch 248/3000\n",
      "700/700 [==============================] - 0s 128us/sample - loss: 0.4031 - acc: 0.8114 - val_loss: 0.6848 - val_acc: 0.7767\n",
      "Epoch 249/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3853 - acc: 0.8100 - val_loss: 0.8018 - val_acc: 0.7833\n",
      "Epoch 250/3000\n",
      "700/700 [==============================] - 0s 132us/sample - loss: 0.3911 - acc: 0.8171 - val_loss: 0.5349 - val_acc: 0.7800\n",
      "Epoch 251/3000\n",
      "700/700 [==============================] - 0s 132us/sample - loss: 0.3971 - acc: 0.8129 - val_loss: 0.5187 - val_acc: 0.7667\n",
      "Epoch 252/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3966 - acc: 0.8114 - val_loss: 0.4978 - val_acc: 0.7900\n",
      "Epoch 253/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3851 - acc: 0.8100 - val_loss: 0.5424 - val_acc: 0.7867\n",
      "Epoch 254/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.4101 - acc: 0.8014 - val_loss: 0.6017 - val_acc: 0.7767\n",
      "Epoch 255/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.3985 - acc: 0.8157 - val_loss: 0.5058 - val_acc: 0.7867\n",
      "Epoch 256/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3959 - acc: 0.8129 - val_loss: 0.5142 - val_acc: 0.7833\n",
      "Epoch 257/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3873 - acc: 0.8186 - val_loss: 0.5464 - val_acc: 0.7900\n",
      "Epoch 258/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.3789 - acc: 0.8171 - val_loss: 0.5964 - val_acc: 0.7900\n",
      "Epoch 259/3000\n",
      "700/700 [==============================] - 0s 161us/sample - loss: 0.3794 - acc: 0.8171 - val_loss: 0.5349 - val_acc: 0.7900\n",
      "Epoch 260/3000\n",
      "700/700 [==============================] - 0s 150us/sample - loss: 0.3872 - acc: 0.8129 - val_loss: 0.5809 - val_acc: 0.7900\n",
      "Epoch 261/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3955 - acc: 0.8114 - val_loss: 0.5638 - val_acc: 0.7900\n",
      "Epoch 262/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4001 - acc: 0.7929 - val_loss: 0.5491 - val_acc: 0.7900\n",
      "Epoch 263/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3902 - acc: 0.8129 - val_loss: 0.5565 - val_acc: 0.7900\n",
      "Epoch 264/3000\n",
      "700/700 [==============================] - 0s 133us/sample - loss: 0.3920 - acc: 0.8129 - val_loss: 0.5299 - val_acc: 0.7900\n",
      "Epoch 265/3000\n",
      "700/700 [==============================] - 0s 134us/sample - loss: 0.3916 - acc: 0.8129 - val_loss: 0.5398 - val_acc: 0.7867\n",
      "Epoch 266/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3862 - acc: 0.8129 - val_loss: 0.5285 - val_acc: 0.7867\n",
      "Epoch 267/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3774 - acc: 0.8157 - val_loss: 0.5670 - val_acc: 0.7867\n",
      "Epoch 268/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3819 - acc: 0.8143 - val_loss: 0.5911 - val_acc: 0.7800\n",
      "Epoch 269/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3793 - acc: 0.8157 - val_loss: 0.6210 - val_acc: 0.7800\n",
      "Epoch 270/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.3836 - acc: 0.8186 - val_loss: 0.5913 - val_acc: 0.7800\n",
      "Epoch 271/3000\n",
      "700/700 [==============================] - 0s 126us/sample - loss: 0.3905 - acc: 0.8071 - val_loss: 0.6051 - val_acc: 0.7767\n",
      "Epoch 272/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3936 - acc: 0.8157 - val_loss: 0.5233 - val_acc: 0.7833\n",
      "Epoch 273/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4115 - acc: 0.8029 - val_loss: 0.5720 - val_acc: 0.7900\n",
      "Epoch 274/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3902 - acc: 0.8200 - val_loss: 0.5166 - val_acc: 0.7867\n",
      "Epoch 275/3000\n",
      "700/700 [==============================] - 0s 124us/sample - loss: 0.3913 - acc: 0.8143 - val_loss: 0.5451 - val_acc: 0.7600\n",
      "Epoch 276/3000\n",
      "700/700 [==============================] - 0s 123us/sample - loss: 0.4162 - acc: 0.8057 - val_loss: 0.5510 - val_acc: 0.7400\n",
      "Epoch 277/3000\n",
      "700/700 [==============================] - 0s 127us/sample - loss: 0.3985 - acc: 0.7729 - val_loss: 0.5265 - val_acc: 0.7900\n",
      "Epoch 278/3000\n",
      "700/700 [==============================] - 0s 141us/sample - loss: 0.3914 - acc: 0.8043 - val_loss: 0.5608 - val_acc: 0.7833\n",
      "Epoch 279/3000\n",
      "700/700 [==============================] - 0s 135us/sample - loss: 0.3827 - acc: 0.8129 - val_loss: 0.5648 - val_acc: 0.7833\n",
      "Epoch 280/3000\n",
      "700/700 [==============================] - 0s 131us/sample - loss: 0.3877 - acc: 0.8157 - val_loss: 0.5159 - val_acc: 0.7867\n",
      "Epoch 281/3000\n",
      "700/700 [==============================] - 0s 130us/sample - loss: 0.3850 - acc: 0.8157 - val_loss: 0.5411 - val_acc: 0.7800\n",
      "Epoch 282/3000\n",
      "700/700 [==============================] - 0s 125us/sample - loss: 0.3895 - acc: 0.8086 - val_loss: 0.5963 - val_acc: 0.7800\n",
      "Epoch 00282: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1cf187501c8>"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train2, \n",
    "          y=y_train2, \n",
    "          epochs=3000, \n",
    "          validation_data=(X_test, y_test),\n",
    "          verbose=1,\n",
    "          callbacks=[early_stop]\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "18facd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_loss=pd.DataFrame(model.history.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971196da",
   "metadata": {},
   "source": [
    "### 5.9 Analisis de pérdida y precisión en las datasets de train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "ee0ec8cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_loss.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4b719924",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test = model.predict(X_test)\n",
    "rounded_test = [round(x[0]) for x in predictions_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "b764a9ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8157143"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_train2, y_train2, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "fd958ace",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "c5c7cc66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c14c38b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "fc2f7a18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.85      0.85      0.85       220\n",
      "         1.0       0.59      0.59      0.59        80\n",
      "\n",
      "    accuracy                           0.78       300\n",
      "   macro avg       0.72      0.72      0.72       300\n",
      "weighted avg       0.78      0.78      0.78       300\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "dd8020fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[187  33]\n",
      " [ 33  47]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee9f64d",
   "metadata": {},
   "source": [
    "Conclusión: \n",
    "- Obtenemos una precisión del 81 en el train y 78 en el test que se considera como aceptable."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
